{
 "cells": [
  {
   "cell_type": "code",
   "id": "5eca0746-e89a-4497-ad96-98d25f3e2b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:10:02.143241Z",
     "start_time": "2025-09-09T19:10:00.456047Z"
    }
   },
   "source": "!pip install --upgrade pandas>=2.0.0\n",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:10:03.618938Z",
     "start_time": "2025-09-09T19:10:02.148623Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade python-dotenv>=1.0.0\n",
   "id": "57e48e4eec1d7285",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:10:05.172487Z",
     "start_time": "2025-09-09T19:10:03.625451Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade transformers>=4.30.0\n",
   "id": "9b91b1a827dbf8cd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:10:06.660008Z",
     "start_time": "2025-09-09T19:10:05.177864Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade torch>=2.0.0\n",
   "id": "4b5078613db30b73",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:10:08.070793Z",
     "start_time": "2025-09-09T19:10:06.666434Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade click>=8.0.0\n",
   "id": "75eebc54e7775c13",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:10:09.455923Z",
     "start_time": "2025-09-09T19:10:08.077469Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade tqdm>=4.65.0\n",
   "id": "8abb23d3bce4c9a2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:10:10.737993Z",
     "start_time": "2025-09-09T19:10:09.462228Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install pandas>=2.0.0 python-dotenv>=1.0.0 transformers>=4.30.0 torch>=2.0.0 click>=8.0.0 tqdm>=4.65.0",
   "id": "899699deb2ca21de",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f644fa57afe26e0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:10:10.962126700Z",
     "start_time": "2025-09-09T19:05:44.254074Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade jupyterlab-widgets ipywidgets\n",
   "id": "5a3bd8864ef46405",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab-widgets in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (3.0.15)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\khala\\medrepo1\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:43:19.699005Z",
     "start_time": "2025-09-09T19:41:30.020233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "CSV Sentiment Analyzer\n",
    "Reads INPUT_FILE from .env and analyzes only 'Coffee D - Notes' column\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from transformers import pipeline\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load .env variables\n",
    "load_dotenv()\n",
    "INPUT_FILE = os.getenv(\"INPUT_FILE\", \"\").strip()\n",
    "OUTPUT_FILE = os.getenv(\"OUTPUT_FILE\", \"results_with_sentiment.csv\").strip()\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    \"\"\"Simple sentiment analyzer for user notes\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"üîÑ Loading sentiment analysis model...\")\n",
    "        try:\n",
    "            self.sentiment_pipeline = pipeline(\n",
    "                \"sentiment-analysis\",\n",
    "                model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "                device=-1,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "            print(\"‚úÖ Model loaded successfully!\")\n",
    "        except Exception:\n",
    "            print(\"‚ö†Ô∏è Using fallback model...\")\n",
    "            self.sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "            print(\"‚úÖ Fallback model loaded!\")\n",
    "\n",
    "    def analyze_text(self, text):\n",
    "        if pd.isna(text) or not str(text).strip():\n",
    "            return \"Neutral\"\n",
    "        try:\n",
    "            clean_text = str(text).strip()[:500]\n",
    "            result = self.sentiment_pipeline(clean_text)[0]\n",
    "            label = result[\"label\"].upper()\n",
    "            if label in [\"POSITIVE\", \"POS\"]:\n",
    "                return \"Positive\"\n",
    "            elif label in [\"NEGATIVE\", \"NEG\"]:\n",
    "                return \"Negative\"\n",
    "            else:\n",
    "                return \"Neutral\"\n",
    "        except Exception:\n",
    "            return \"Neutral\"\n",
    "\n",
    "    def analyze_csv(self, input_file, output_file):\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"‚ùå File not found: {input_file}\")\n",
    "            return None\n",
    "\n",
    "        df = pd.read_csv(input_file)\n",
    "\n",
    "        target_col = \"Coffee D - Notes\"\n",
    "        if target_col not in df.columns:\n",
    "            print(f\"‚ùå Column '{target_col}' not found in CSV!\")\n",
    "            print(f\"Available columns: {list(df.columns)}\")\n",
    "            return df\n",
    "\n",
    "        sentiments = [self.analyze_text(text) for text in df[target_col]]\n",
    "        df[f\"{target_col}_Sentiment\"] = sentiments\n",
    "\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"üíæ Results saved to: {output_file}\")\n",
    "        return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not INPUT_FILE:\n",
    "        print(\"‚ùå Please set INPUT_FILE in your .env\")\n",
    "    else:\n",
    "        analyzer = SentimentAnalyzer()\n",
    "        analyzer.analyze_csv(INPUT_FILE, OUTPUT_FILE)\n"
   ],
   "id": "51d87b27dc7f0b8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading sentiment analysis model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully!\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\khala\\\\OneDrive\\\\Desktop\\\\Coffee_Ch\\\\New folder'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPermissionError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 80\u001B[39m\n\u001B[32m     78\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     79\u001B[39m     analyzer = SentimentAnalyzer()\n\u001B[32m---> \u001B[39m\u001B[32m80\u001B[39m     \u001B[43manalyzer\u001B[49m\u001B[43m.\u001B[49m\u001B[43manalyze_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mINPUT_FILE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mOUTPUT_FILE\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 71\u001B[39m, in \u001B[36mSentimentAnalyzer.analyze_csv\u001B[39m\u001B[34m(self, input_file, output_file)\u001B[39m\n\u001B[32m     68\u001B[39m sentiments = [\u001B[38;5;28mself\u001B[39m.analyze_text(text) \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m df[target_col]]\n\u001B[32m     69\u001B[39m df[\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget_col\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_Sentiment\u001B[39m\u001B[33m\"\u001B[39m] = sentiments\n\u001B[32m---> \u001B[39m\u001B[32m71\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33müíæ Results saved to: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput_file\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     73\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\medrepo1\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001B[39m, in \u001B[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    327\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) > num_allow_args:\n\u001B[32m    328\u001B[39m     warnings.warn(\n\u001B[32m    329\u001B[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001B[32m    330\u001B[39m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m    331\u001B[39m         stacklevel=find_stack_level(),\n\u001B[32m    332\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m333\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\medrepo1\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001B[39m, in \u001B[36mNDFrame.to_csv\u001B[39m\u001B[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[39m\n\u001B[32m   3975\u001B[39m df = \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.to_frame()\n\u001B[32m   3977\u001B[39m formatter = DataFrameFormatter(\n\u001B[32m   3978\u001B[39m     frame=df,\n\u001B[32m   3979\u001B[39m     header=header,\n\u001B[32m   (...)\u001B[39m\u001B[32m   3983\u001B[39m     decimal=decimal,\n\u001B[32m   3984\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m3986\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3987\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3988\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3989\u001B[39m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[43m=\u001B[49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3990\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3991\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3992\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3993\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3994\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3995\u001B[39m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3996\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3997\u001B[39m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3998\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3999\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4000\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4001\u001B[39m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4002\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4003\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\medrepo1\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001B[39m, in \u001B[36mDataFrameRenderer.to_csv\u001B[39m\u001B[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[39m\n\u001B[32m    993\u001B[39m     created_buffer = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    995\u001B[39m csv_formatter = CSVFormatter(\n\u001B[32m    996\u001B[39m     path_or_buf=path_or_buf,\n\u001B[32m    997\u001B[39m     lineterminator=lineterminator,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1012\u001B[39m     formatter=\u001B[38;5;28mself\u001B[39m.fmt,\n\u001B[32m   1013\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m1014\u001B[39m \u001B[43mcsv_formatter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[32m   1017\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\medrepo1\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001B[39m, in \u001B[36mCSVFormatter.save\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    247\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    248\u001B[39m \u001B[33;03mCreate the writer & save.\u001B[39;00m\n\u001B[32m    249\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    250\u001B[39m \u001B[38;5;66;03m# apply compression and byte/text conversion\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    256\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    257\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    258\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[32m    259\u001B[39m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[32m    260\u001B[39m     \u001B[38;5;28mself\u001B[39m.writer = csvlib.writer(\n\u001B[32m    261\u001B[39m         handles.handle,\n\u001B[32m    262\u001B[39m         lineterminator=\u001B[38;5;28mself\u001B[39m.lineterminator,\n\u001B[32m   (...)\u001B[39m\u001B[32m    267\u001B[39m         quotechar=\u001B[38;5;28mself\u001B[39m.quotechar,\n\u001B[32m    268\u001B[39m     )\n\u001B[32m    270\u001B[39m     \u001B[38;5;28mself\u001B[39m._save()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\medrepo1\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mPermissionError\u001B[39m: [Errno 13] Permission denied: 'C:\\\\Users\\\\khala\\\\OneDrive\\\\Desktop\\\\Coffee_Ch\\\\New folder'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:47:47.008063Z",
     "start_time": "2025-09-09T19:46:01.139364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "CSV Sentiment Analyzer\n",
    "Reads INPUT_FILE from .env, analyzes 'Coffee D - Notes' column,\n",
    "and updates the same CSV file with a new sentiment column\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from transformers import pipeline\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load .env variables\n",
    "load_dotenv()\n",
    "INPUT_FILE = os.getenv(\"INPUT_FILE\", \"\").strip()\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    \"\"\"Simple sentiment analyzer for user notes\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"üîÑ Loading sentiment analysis model...\")\n",
    "        try:\n",
    "            self.sentiment_pipeline = pipeline(\n",
    "                \"sentiment-analysis\",\n",
    "                model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "                device=-1,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "            print(\"‚úÖ Model loaded successfully!\")\n",
    "        except Exception:\n",
    "            print(\"‚ö†Ô∏è Using fallback model...\")\n",
    "            self.sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "            print(\"‚úÖ Fallback model loaded!\")\n",
    "\n",
    "    def analyze_text(self, text):\n",
    "        if pd.isna(text) or not str(text).strip():\n",
    "            return \"Neutral\"\n",
    "        try:\n",
    "            clean_text = str(text).strip()[:500]\n",
    "            result = self.sentiment_pipeline(clean_text)[0]\n",
    "            label = result[\"label\"].upper()\n",
    "            if label in [\"POSITIVE\", \"POS\"]:\n",
    "                return \"Positive\"\n",
    "            elif label in [\"NEGATIVE\", \"NEG\"]:\n",
    "                return \"Negative\"\n",
    "            else:\n",
    "                return \"Neutral\"\n",
    "        except Exception:\n",
    "            return \"Neutral\"\n",
    "\n",
    "    def analyze_csv_inplace(self, input_file):\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"‚ùå File not found: {input_file}\")\n",
    "            return None\n",
    "\n",
    "        df = pd.read_csv(input_file)\n",
    "\n",
    "        target_col = \"Coffee D - Notes\"\n",
    "        if target_col not in df.columns:\n",
    "            print(f\"‚ùå Column '{target_col}' not found in CSV!\")\n",
    "            print(f\"Available columns: {list(df.columns)}\")\n",
    "            return df\n",
    "\n",
    "        # ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿπŸÖŸàÿØ Ÿàÿ•ÿ∂ÿßŸÅÿ© ÿπŸÖŸàÿØ ÿ¨ÿØŸäÿØ\n",
    "        df[f\"{target_col}_Sentiment\"] = [self.analyze_text(text) for text in df[target_col]]\n",
    "\n",
    "        # ÿ≠ŸÅÿ∏ ÿßŸÑÿ™ÿπÿØŸäŸÑÿßÿ™ ÿπŸÑŸâ ŸÜŸÅÿ≥ ÿßŸÑŸÖŸÑŸÅ\n",
    "        df.to_csv(input_file, index=False)\n",
    "        print(f\"üíæ File updated successfully with new column: '{target_col}_Sentiment'\")\n",
    "        return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not INPUT_FILE:\n",
    "        print(\"‚ùå Please set INPUT_FILE in your .env\")\n",
    "    else:\n",
    "        analyzer = SentimentAnalyzer()\n",
    "        analyzer.analyze_csv_inplace(INPUT_FILE)\n"
   ],
   "id": "84029b71b76fe598",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading sentiment analysis model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully!\n",
      "üíæ File updated successfully with new column: 'Coffee D - Notes_Sentiment'\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a4e60dc5d312bbd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
